{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "# import required module\n",
    "import unidecode\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "result = []\n",
    "for i in range(1, 11):\n",
    "    html = requests.get(f\"http://quotes.toscrape.com/page/{i}\")\n",
    "    html_tree = BeautifulSoup(html.text)\n",
    "    authors_blocks = html_tree.find_all(\"div\", class_=\"quote\")\n",
    "    for author_block in authors_blocks:\n",
    "        text = author_block.find(\"span\", attrs={\"class\":\"text\"}).text\n",
    "        author = author_block.find(\"small\", attrs={\"class\":\"author\"}).text\n",
    "        tags = \" \".join([tag.text for tag in author_block.find_all(\"a\", attrs={\"class\":\"tag\"})]) \n",
    "        result.append([author, text, tags])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:17<00:00,  2.86it/s]\n"
     ]
    }
   ],
   "source": [
    "authors_names = [item[0] for item in result]\n",
    "authors_names = list(set(authors_names))\n",
    "result2 = []\n",
    "\n",
    "for name in tqdm(authors_names):\n",
    "    new_name = name.replace(\".\", \" \")\n",
    "    new_name = unidecode.unidecode(new_name)\n",
    "    html = requests.get(f\"http://quotes.toscrape.com/author/{'-'.join(new_name.split())}\")\n",
    "    html_tree = BeautifulSoup(html.text)\n",
    "    birthday = html_tree.find(\"span\", attrs={\"class\":\"author-born-date\"}).text\n",
    "    location = html_tree.find(\"span\", attrs={\"class\":\"author-born-location\"}).text\n",
    "    description = html_tree.find(\"div\", attrs={\"class\":\"author-description\"}).text\n",
    "    result2.append([name, birthday, location, description])    \n",
    "df = pd.DataFrame(result2, columns=[\"name\", \"birthday\", \"location\", \"description\"])        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you find the asyncio implemetion which is much faster than the standard syncronuous implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: aiohttp in /home/robyavo/.local/lib/python3.10/site-packages (3.9.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/robyavo/.local/lib/python3.10/site-packages (from aiohttp) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/robyavo/.local/lib/python3.10/site-packages (from aiohttp) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/robyavo/.local/lib/python3.10/site-packages (from aiohttp) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/robyavo/.local/lib/python3.10/site-packages (from aiohttp) (23.1.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/robyavo/.local/lib/python3.10/site-packages (from aiohttp) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/robyavo/.local/lib/python3.10/site-packages (from aiohttp) (1.9.3)\n",
      "Requirement already satisfied: idna>=2.0 in /home/robyavo/.local/lib/python3.10/site-packages (from yarl<2.0,>=1.0->aiohttp) (3.4)\n"
     ]
    }
   ],
   "source": [
    "! pip install aiohttp # install aiohttp if you haven't already"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 537731.28it/s]\n"
     ]
    }
   ],
   "source": [
    "import aiohttp\n",
    "import asyncio\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "import unidecode\n",
    "# List of authors' names from your result\n",
    "authors_names = [item[0] for item in result]\n",
    "authors_names = list(set(authors_names))\n",
    "result2 = []\n",
    "\n",
    "async def fetch_author_info(session, name):\n",
    "    new_name = name.replace(\".\", \" \")\n",
    "    new_name = unidecode.unidecode(new_name)\n",
    "    async with session.get(f\"http://quotes.toscrape.com/author/{'-'.join(new_name.split())}\") as response:\n",
    "        html = await response.text()\n",
    "        html_tree = BeautifulSoup(html, \"html.parser\")\n",
    "        birthday = html_tree.find(\"span\", attrs={\"class\": \"author-born-date\"}).text\n",
    "        location = html_tree.find(\"span\", attrs={\"class\": \"author-born-location\"}).text\n",
    "        description = html_tree.find(\"div\", attrs={\"class\": \"author-description\"}).text\n",
    "        return [name, birthday, location, description]\n",
    "\n",
    "\n",
    "async with aiohttp.ClientSession() as session:\n",
    "    tasks = [fetch_author_info(session, name) for name in tqdm(authors_names)]\n",
    "    result2.extend(await asyncio.gather(*tasks))\n",
    "df = pd.DataFrame(result2, columns=[\"name\", \"birthday\", \"location\", \"description\"])    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
